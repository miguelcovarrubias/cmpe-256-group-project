{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "# Enter your keys/secrets as strings in the following fields\n",
    "credentials = {}  \n",
    "credentials['CONSUMER_KEY'] = REPLACEME\n",
    "credentials['CONSUMER_SECRET'] = REPLACEME\n",
    "credentials['ACCESS_TOKEN'] = REPLACEME\n",
    "credentials['ACCESS_SECRET'] = REPLACEME\n",
    "\n",
    "# Save the credentials object to file\n",
    "with open(\"twitter_credentials.json\", \"w\") as file:  \n",
    "    json.dump(credentials, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython  \n",
    "import json\n",
    "\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:  \n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_urls = []\n",
    "MAX_ATTEMPTS = 2000\n",
    "COUNT_OF_URLS_TO_BE_FETCHED = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,MAX_ATTEMPTS):\n",
    "\n",
    "    if(COUNT_OF_URLS_TO_BE_FETCHED < len(spotify_urls)):\n",
    "        break # we got 5000 urls... !!\n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    # STEP 1: Query Twitter\n",
    "    # STEP 2: Save the returned tweets\n",
    "    # STEP 3: Get the next max_id\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    # STEP 1: Query Twitter\n",
    "    if(0 == i):\n",
    "        # Query twitter for data. \n",
    "        results = python_tweets.search(q=\"url:open.spotify.com/playlist\", include_entities='true', count='100')\n",
    "    else:\n",
    "        # After the first call we should have max_id from result of previous call. Pass it in query.\n",
    "        results = python_tweets.search(q=\"url:open.spotify.com/playlist\", include_entities='true',max_id=next_max_id)\n",
    "\n",
    "    # STEP 2: Save the returned tweets\n",
    "    for result in results['statuses']:\n",
    "        entities = result['entities']\n",
    "        for entity in entities:\n",
    "            if entity == 'urls':\n",
    "                urls = entities['urls']\n",
    "                for url in urls:\n",
    "                    if(url['expanded_url'] and 'open.spotify.com/playlist' in url['expanded_url']):\n",
    "                        playlist_url = url['expanded_url']\n",
    "                        spotify_urls.append(playlist_url)\n",
    "                        \n",
    "\n",
    "    # STEP 3: Get the next max_id\n",
    "    try:\n",
    "        # Parse the data returned to get max_id to be passed in consequent call.\n",
    "        next_results_url_params = results['search_metadata']['next_results']\n",
    "        next_max_id = next_results_url_params.split('max_id=')[1].split('&')[0]\n",
    "        rate_limit_remaining = python_tweets.get_lastfunction_header('x-rate-limit-remaining')\n",
    "        print(rate_limit_remaining)\n",
    "        if int(rate_limit_remaining) < 25:\n",
    "            rate_limit_remaining = python_tweets.get_lastfunction_header('x-rate-limit-remaining')\n",
    "            print(\"Next Max Id: {}\".format(next_max_id))\n",
    "            print(\"Rate limit remaining: {}\".format(rate_limit_remaining))\n",
    "            print(\"Number of urls scraped: {}\".format(len(spotify_urls)))\n",
    "        time.sleep(2.2)\n",
    "    except Exception as e:\n",
    "        # No more next pages\n",
    "        print(e)\n",
    "        print('no more')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spotify_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_urls = set(spotify_urls)\n",
    "with open('playlist.csv', 'w') as f:\n",
    "    for url in final_urls:\n",
    "        f.write(\"%s\\n\" % url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
